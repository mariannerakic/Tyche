<!DOCTYPE html>

<html lang="en">

<head>
    <link rel="shortcut icon" href="./assets/favicon.ico">
    <meta name="description" content="Stochastic In-Context Learning for Medical Image Segmentation">
    <meta name="keywords" content="Tyche,Segmentation,In-Context Learning, Uncertainty,Medical,Neural-Networks">
    <title>Tyche</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
    <script src="https://kit.fontawesome.com/d3e95fa766.js" crossorigin="anonymous"></script>
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"rel="stylesheet">
    <link rel="stylesheet" href="./assets/css/style.css">
    <link rel="stylesheet" href="./assets/css/index.css">
</head>

<body>

<div class="jumbotron is-centered">

  <div class="desktop-only">
    <div class="container text-center">
      <h1>Tyche</h1>
      <h3>Stochastic In-Context Learning for Medical Image Segmentation</h3>
      <h2></h2>
    </div>

    <div class="table-like authors" style="justify-content:space-evenly;max-width:880px;margin:auto;">
      <div>
        <center>
          <a href="https://mariannerakic.github.io/" style="font-size: larger">Marianne Rakic</a>
        </center>
        <center>
          MIT CSAIL & MGH
        </center>
      </div>
      <div>
        <center>
          <a href="https://halleewong.github.io/" style="font-size: larger">Hallee E. Wong</a>
        </center>
        <center>
          MIT CSAIL & MGH
        </center>
      </div>
      <div>
        <center>
          <a href="https://josejg.com/" style="font-size: larger">Jose Javier Gonzalez Ortiz</a>
        </center>
        <center>
          MosaicML DataBricks & MIT
        </center>
      </div>
    </div> 
    <div class="table-like authors" style="justify-content:space-evenly;max-width:880px;margin:auto;">    
      <div>
        <center>
          <a href="https://www.broadinstitute.org/bios/beth-cimini" style="font-size: larger">Beth Cimini</a>
        </center>
        <center>
          Broad Institute
        </center>
      </div>
      <div>
        <center>
          <a href="https://people.csail.mit.edu/guttag/" style="font-size: larger">John Guttag</a>
        </center>
        <center>
          MIT CSAIL
        </center>
      </div>
      <div>
        <center>
          <a href="http://www.mit.edu/~adalca/" style="font-size: larger">Adrian V. Dalca</a>
        </center>
        <center>
          MIT CSAIL & HMS MGH
        </center>
      </div>
    </div>
    <div>
        <center>
            <h3 style="font-weight: bold; color: #f68946"> CVPR 2024 </h3>
        </center>
    </div>
  </div>

  <div class="mobile-only">
    <div class="container text-center">
      <h1 style="font-size:13vw">Tyche</h1>
      <h3>Stochastic In-Context Learning for Medical Image Segmentation</h3>
      <h2></h2>
    </div>

    <div class="table-like authors" style="justify-content:space-evenly;max-width:880px;margin:auto;">
      <div>
        <center>
          <a href="https://mariannerakic.github.io/" style="font-size: larger; padding: 0em 2em">Marianne Rakic</a>
        </center>
        <center>
          MIT CSAIL & MGH
        </center>
      </div>

      <div>
        <center>
          <a href="https://halleewong.github.io/" style="font-size: larger; padding: 0em 2em">Hallee E. Wong</a>
        </center>
        <center>
          MIT CSAIL & MGH
        </center>
      </div>

      <div>
        <center>
          <a href="https://josejg.com/" style="font-size: larger; padding: 0em 2em">Jose Javier Gonzalez Ortiz</a>
        </center>
        <center>
          MIT CSAIL
        </center>
      </div>
    </div>
    <div class="table-like authors" style="justify-content:space-evenly;max-width:880px;margin:auto;">  
      <div>
        <center>
          <a href="https://www.broadinstitute.org/bios/beth-cimini" style="font-size: larger; padding: 0em 2em">Beth Cimini</a>
        </center>
        <center>
          Broad Institute
        </center>
      </div>
      <div>
        <center>
          <a href="https://people.csail.mit.edu/guttag/" style="font-size: larger; padding: 0em 2em">John Guttag</a>
        </center>
        <center>
          MosaicML DataBricks & MIT CSAIL
        </center>
      </div>
      <div>
        <center>
          <a href="http://www.mit.edu/~adalca/" style="font-size: larger; padding: 0em 2em">Adrian V. Dalca</a>
        </center>
        <center>
          MIT CSAIL & HMS, MGH
        </center>
      </div>
    </div>
    <div>
        <center>
            <h3 style="font-weight: bold; color: #f68946"> CVPR 2024 </h3>
        </center>
    </div>
  <!-- </center> -->
  </div>

</div>

<div class="container is-centered">
        <div class="row text-center">

        <a href="http://arxiv.org/abs/2401.13650" target="_blank">
            <button class="button-link">
            <i class="fa-regular fa-file-lines fa-lg" style="color: #ffffff;"></i>
            &nbsp;Paper
        </button>
        </a>

        <a href="https://github.com/mariannerakic/tyche" target="_blank">
        <button class="button-link">
            <i class="fa-brands fa-github fa-lg" style="color: #ffffff;"></i>
            &nbsp;Code
        </button>
        </a>

        <a href="https://colab.research.google.com/drive/13cbnhL2j5ify21TdtiR00j3yPKbs2QYI?usp=sharing" target="_blank">
        <button class="button-link">
            <svg height="20" width="30" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><title>Google Colab</title><path fill="#F9AB00" fill-rule="evenodd" d="M16.9414 4.9757a7.033 7.033 0 0 0-4.9308 2.0646 7.033 7.033 0 0 0-.1232 9.8068l2.395-2.395a3.6455 3.6455 0 0 1 5.1497-5.1478l2.397-2.3989a7.033 7.033 0 0 0-4.8877-1.9297zM7.07 4.9855a7.033 7.033 0 0 0-4.8878 1.9316l2.3911 2.3911a3.6434 3.6434 0 0 1 5.0227.1271l1.7341-2.9737-.0997-.0802A7.033 7.033 0 0 0 7.07 4.9855zm15.0093 2.1721l-2.3892 2.3911a3.6455 3.6455 0 0 1-5.1497 5.1497l-2.4067 2.4068a7.0362 7.0362 0 0 0 9.9456-9.9476zM1.932 7.1674a7.033 7.033 0 0 0-.002 9.6816l2.397-2.397a3.6434 3.6434 0 0 1-.004-4.8916zm7.664 7.4235c-1.38 1.3816-3.5863 1.411-5.0168.1134l-2.397 2.395c2.4693 2.3328 6.263 2.5753 9.0072.5455l.1368-.1115z"/></svg>
            Colab
        </button>
        </a>

    </div>

</div>


<section class="section">
  <div class="container is-max-desktop">
    <h2 class="text-center ">Overview</h2>
    <hr/>
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <p>
          We present Tyche, a stochastic strategy for in-context medical image segmentation, to both generalize to new tasks and capture uncertainty
          <br>
          <br>
          Tyche produces multiple candidate segmentations for images  from unseen biomedical datasets without retraining fine-tuning
          <br>
            <div class="row ">
                <div class="col-sm-10 col-sm-offset-1 text-center">
                    <img src="assets/images/teaser_pred.png" class="img-responsive
                        " style="width:100% " alt="Image ">
                </div>
            </div>
        </p>
      </div>
    </div>
  </div>
</section>
    
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="text-center ">Abstract</h2>
    <hr/>
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <p>
          Existing learning-based solutions to medical image segmentation have two important shortcomings.
          <br>
          <br>
          First, for each new segmentation task, usually a new model has to be trained or fine-tuned. This requires extensive resources and machine-learning expertise, and is therefore often infeasible for medical researchers and clinicians. Second, most existing segmentation methods produce a single deterministic segmentation mask for a given image. However, in practice, there is often considerable uncertainty about what constitutes the correct segmentation, and different expert annotators will often segment the same image differently. </b> 
          <br>
          <br>
          We tackle both of these problems with <b>Tyche</b>, a model that uses a context set to generate stochastic predictions for previously unseen tasks without the need to retrain. Tyche differs from other in-context segmentation methods in two important ways.  
          <br>
          <br>
          (1) We introduce a novel convolution block architecture that enables interactions among predictions. 
          (2) We introduce in-context test-time augmentation, a new mechanism to provide prediction stochasticity. 
          <br>
          <br>
          When combined with appropriate model design and loss functions, Tyche can predict a set of plausible diverse segmentation candidates for new or unseen medical images and segmentation tasks without the need to retrain.
          <div class="row ">
            <div class="col-sm-10 col-sm-offset-1 text-center">
            <img src="assets/images/gaps.png" class="img-responsive
                " style="width:100% " alt="Image ">
            </div>
          </div>
        </p>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="text-center ">Methods</h2>
    <hr/>
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <p>
          Tyche captures the inherent ambiguity in medical image segmentation, while generalizing to new tasks without the need to retrain.
          <br>
          <br>
          Tyche uses an input context set of image-segmentation pairs, which define the segmentation task, to know how to segment an input target image. Crucially, it captures uncertainty by outputting a flexible number of plausible predictions.
          <br>
          <div class="row ">
            <div class="col-sm-10 col-sm-offset-1 text-center">
            <img src="assets/images/inputoutput.png" class="img-responsive
                " style="width:100% " alt="Image ">
            </div>
          </div>
          <br>
          We captures uncertainty through:
          <br>
          <br>
          (1) Best candidate Dice loss (to hedge its bets), that encourages diversity by backpropagating gradients only for the best prediction. 
          (2) SetBlock, an architectural mechanism for the predictions to interact at each layer.
          <br>
          <br>
          <div class="row ">
            <div class="col-sm-10 col-sm-offset-1 text-center">
            <img src="assets/images/methods.png" class="img-responsive
                " style="width:100% " alt="Image ">
            </div>
          </div>
        </p>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="text-center ">Visualizations</h2>
    <hr/>
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <p>
        Tyche accurately captures ambiguity in target images by providing plausible, diverse solutions even for new, previously unseen segmentation domains and targets. 
          <br>
          <br>
         Multi-annotator data examples:
          <div class="row ">
            <div class="col-sm-10 col-sm-offset-1 text-center">
            <img src="assets/images/examples_ma.png" class="img-responsive
                " style="width:100% " alt="Image ">
            </div>
         <br>
         <br>
         Single-annotator data examples:
          </div>
            <div class="row ">
            <div class="col-sm-10 col-sm-offset-1 text-center">
            <img src="assets/images/examples_sa.png" class="img-responsive
                " style="width:100% " alt="Image ">
            </div>
          </div>
        </p>
      </div>
    </div>
  </div>
</section>


</section>

<div class="container">
  <div class="row is-four-fifths">
    <h2 class="text-center ">Citation</h2>
    <hr/>
    <p>If you find our work or any of our materials useful, please cite our paper:</p>
    <div class="alert alert-light citation">
        @inproceedings{rakic2024tyche,<br>
          &nbsp;&nbsp;title={Tyche: Stochastic In-Context Learning for Medical Image Segmentation},<br>
          &nbsp;&nbsp;author={Marianne Rakic and Hallee E. Wong and Jose Javier Gonzalez Ortiz and Beth Cimini and John V. Guttag and Adrian V. Dalca},<br>
          &nbsp;&nbsp;booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},<br>
          &nbsp;&nbsp;year={2024},<br>
    }
    </div>
  </div>
</div>


<br>
<br>


</body>
</html>
